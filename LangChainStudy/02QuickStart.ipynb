{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 02. langchain的快速入门\n",
    "https://python.langchain.com/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# llm = OpenAI(openai_api_key=\"...\") # 如果你有openai的api key，可以在这里填入\n",
    "llm = OpenAI() # 这种写法是通过系统环境变量获取openai的api key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### 环境变量设置\n",
    "第一步，按下“win+r”键，打开运行框，\n",
    "\n",
    "第二步，输入命令“control system”,\n",
    "\n",
    "第三步，在控制面板主页，打开“高级系统设置”，\n",
    "\n",
    "第四步，在高级系统设置界面，选择“环境变量”选项，\n",
    "\n",
    "第五步，根据需求进行设置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:05:33.971900Z",
     "start_time": "2023-08-06T12:05:33.963902Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#设置代理\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7809'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7809'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2.1. 构建应用程序\n",
    "现在我们可以开始构建语言模型应用程序了。LangChain提供了许多可用于构建语言模型应用程序的模块。模块可以在简单的应用程序中作为独立模块使用，并且可以组合用于更复杂的用例。在本节中，我们将介绍如何使用LangChain的模块来构建一个简单的应用程序。\n",
    "\n",
    "LangChain应用程序的核心构建块是LLMChain。这结合了三件事：\n",
    "\n",
    "    1.LLM：语言模型是这里的核心推理引擎。为了使用 LangChain，您需要了解不同类型的语言模型以及如何使用它们。\n",
    "\n",
    "    2.提示模板：这为语言模型提供说明。这控制语言模型输出的内容，因此了解如何构造提示和不同的提示策略至关重要。\n",
    "\n",
    "    3.输出解析器：这些将来自LLM的原始响应转换为更可行的格式，从而可以轻松使用下游的输出。\n",
    "\n",
    "我们将单独介绍这三个组件，然后介绍组合所有这些组件的LLMChain。\n",
    "\n",
    "了解这些概念将为您能够使用和自定义 LangChain 应用程序做好准备。\n",
    "\n",
    "大多数LangChain应用程序都允许您配置LLM和/或使用的提示，因此知道如何利用这一点将是一个很大的推动因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.1.1. LLMs\n",
    "有两种类型的语言模型，在LangChain中称为：\n",
    "```\n",
    "llms：这是一个语言模型，它将字符串作为输入并返回一个字符串\n",
    "chat_models：这是一种语言模型，它将消息列表作为输入并返回消息\n",
    "```\n",
    "\n",
    "LLM 的输入/输出简单易懂 - 一个字符串。\n",
    "\n",
    "但是chat_models呢？\n",
    "\n",
    "那里的输入是ChatMessage的列表 ，输出是单个ChatMessage .\n",
    "\n",
    "一个ChatMessage有两个必需的组件：\n",
    "```\n",
    "content ：这是消息的内容。\n",
    "role ：这是来自的 ChatMessage 实体的角色。\n",
    "```\n",
    "LangChain 提供了几个对象来轻松区分不同的角色：\n",
    "```\n",
    "HumanMessage ： ChatMessage来自人类/用户。\n",
    "\n",
    "AIMessage ： ChatMessage来自AI/助手。\n",
    "\n",
    "SystemMessage ：来自系统的ChatMessage 。\n",
    "\n",
    "FunctionMessage ：来自函数调用的ChatMessage 。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "LangChain 为两者公开了一个标准接口，但了解这种差异以便为给定语言模型构造提示很有用。LangChain 公开的标准接口有两种方法：\n",
    "\n",
    "invoke ：接受字符串，返回字符串\n",
    "\n",
    "invoke ：接收消息列表，返回消息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T15:51:07.077669Z",
     "start_time": "2023-08-06T15:51:07.050846Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n你好！我是一个人工智能助手，很高兴认识你。有什么可以帮到你的吗？'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()\n",
    "llm.invoke(\"你好!\")\n",
    "# chat_model.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T15:52:00.433996Z",
     "start_time": "2023-08-06T15:51:58.253136Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9d51be5e-407a-4e03-bc90-41b47927bea8-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T15:52:01.928783Z",
     "start_time": "2023-08-06T15:52:00.782208Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHola!\\n\\n¿Cómo estás?\\n\\nEstoy bien, gracias. ¿Y tú?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T15:52:49.092752Z",
     "start_time": "2023-08-06T15:52:47.426474Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n七彩袜子有限公司'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?请用中文回答\"\n",
    "\n",
    "llm.invoke(text)\n",
    "# >> Feetful of Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T15:52:58.396183Z",
     "start_time": "2023-08-06T15:52:57.503066Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='缤纷袜业', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 29, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b3c23c62-f88d-45fd-bb59-7c00afd0dc5e-0', usage_metadata={'input_tokens': 29, 'output_tokens': 7, 'total_tokens': 36})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(text)\n",
    "# >> Socks O'Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:14:31.483788Z",
     "start_time": "2023-08-06T12:14:31.467790Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "text = \"怎样才能年入百万？\"\n",
    "\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:14:33.690209Z",
     "start_time": "2023-08-06T12:14:32.892817Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Rainbow Threads', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages)\n",
    "# >> Socks O'Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:14:39.849929Z",
     "start_time": "2023-08-06T12:14:37.786630Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nSocktacular!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)\n",
    "# >> Feetful of Fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "对于这两种方法，还可以将参数作为关键字参数传入。\n",
    "\n",
    "例如，您可以传入 temperature=0 以根据对象的配置调整使用的温度。在运行时传入的任何值都将始终覆盖对象配置的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:16:52.085650Z",
     "start_time": "2023-08-06T12:16:50.746953Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='要实现年入百万的目标，需要具备以下几个关键要素：\\n\\n1. 找到一个高收入的职业或创业机会：选择一个高薪职业或创业项目，比如医生、律师、投资者、企业家等，能够带来稳定且丰厚的收入。\\n\\n2. 不断提升自己的技能和知识：通过学习、培训和实践，不断提升自己的专业技能和知识水平，以提高自己在职场上的竞争力和价值。\\n\\n3. 善于投资和理财：学会理财规划和投资，让自己的资产增值，实现财务自由和财富积累。\\n\\n4. 勤奋努力和坚持不懈：要有足够的毅力和耐心，坚持不懈地努力工作和追求目标，不断挑战自己，才能实现年入百万的目标。\\n\\n5. 寻找多元化的收入来源：除了主要的工作或创业项目外，还可以寻找其他的收入来源，比如投资、副业、兼职等，以增加收入来源和多样化风险。\\n\\n总之，要实现年入百万的目标，需要具备正确的职业选择、不断提升自己的能力、善于理财和投资、坚持努力和寻找多元化的收入来源等要素。只有全方位地提升自己，才能实现财务自由和财富积累。', response_metadata={'token_usage': {'completion_tokens': 471, 'prompt_tokens': 19, 'total_tokens': 490}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cdea10cc-38cf-4f1e-8be1-9b77d51125b1-0', usage_metadata={'input_tokens': 19, 'output_tokens': 471, 'total_tokens': 490})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:16:58.988274Z",
     "start_time": "2023-08-06T12:16:58.280418Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='要年入百万，通常需要具备以下几个条件：\\n\\n1. 选择一个高收入的行业或职业：选择一个高薪行业或职业，比如金融、科技、医疗等，能够为你提供更多赚钱的机会。\\n\\n2. 不断提升自己的技能和知识：不断学习和提升自己的技能和知识，可以让你在职场上更有竞争力，从而获得更高的薪水。\\n\\n3. 创业或投资：创业或投资是实现年入百万的有效途径之一。通过创业或投资，可以获得更高的回报和收入。\\n\\n4. 节约开支和理性消费：要年入百万，不仅需要增加收入，还需要控制开支，节约开支和理性消费是实现财务自由的重要前提。\\n\\n5. 善于理财和投资：善于理财和投资可以让你的资产增值，获得更多的财富积累。\\n\\n总的来说，要年入百万，需要不断提升自己的能力和技能，选择合适的行业和职业，控制开支，理性消费，创业或投资等多种因素综合作用。', response_metadata={'token_usage': {'completion_tokens': 377, 'prompt_tokens': 19, 'total_tokens': 396}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0fc4eaf3-de81-4346-9a38-684c9661b7fb-0', usage_metadata={'input_tokens': 19, 'output_tokens': 377, 'total_tokens': 396})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages,temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:17:05.186200Z",
     "start_time": "2023-08-06T12:17:04.429252Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='要想年入百万，通常需要具备以下条件和做法：\\n\\n1. 拥有高收入职业：选择一份高薪职业或者行业，比如金融、科技、医疗等领域的高薪工作。\\n\\n2. 创业或投资：创业或投资是实现年入百万的一种途径，可以寻找有潜力的项目或领域进行投资或自主创业。\\n\\n3. 学习和提升自我：不断学习和提升自己的能力，增强自己在职场上的竞争力，从而获得更高的报酬。\\n\\n4. 精打细算：在日常生活中控制开支，合理规划资金运用，避免浪费，增加储蓄和投资的机会。\\n\\n5. 多元化收入来源：除了主要工作外，还可以通过副业、兼职、投资等方式获取额外收入，实现收入的多元化。\\n\\n6. 善于理财：学会理财和投资管理，让资金更有效地运转和增值，实现年入百万的目标。\\n\\n总之，要年入百万需要有正确的职业选择、积极进取的心态、精明的理财规划和持续的努力和学习。', response_metadata={'token_usage': {'completion_tokens': 391, 'prompt_tokens': 19, 'total_tokens': 410}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-573be3a4-5882-4cc8-ac82-54a2c3f91245-0', usage_metadata={'input_tokens': 19, 'output_tokens': 391, 'total_tokens': 410})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages,temperature=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.1.2. 提示模板\n",
    "大多数LLM应用程序不会将用户输入直接传递到LLM。\n",
    "通常，他们会将用户输入添加到称为提示模板的较大文本中，该文本为手头的特定任务提供额外的上下文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:22:05.356534Z",
     "start_time": "2023-08-06T12:22:05.326533Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "提示模板还可用于生成消息列表。在这种情况下，提示不仅包含有关内容的信息，还包含每条消息（其角色，其在列表中的位置等）在这里，最常发生的是聊天提示模板是聊天消息模板的列表。\n",
    "每个聊天消息模板都包含有关如何格式化该聊天消息的说明 - 它的角色，然后是它的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:23:01.981472Z",
     "start_time": "2023-08-06T12:23:01.940376Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to chinese.', additional_kwargs={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt = chat_prompt.format_messages(input_language=\"English\", output_language=\"chinese\", text=\"I love programming.\")\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:23:22.292505Z",
     "start_time": "2023-08-06T12:23:18.308241Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\n系統：我愛編程。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(chat_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.1.3. 输出解析器\n",
    "输出解析器将LLM的原始输出转换为可以在下游使用的格式。输出分析器的主要类型很少，包括：\n",
    "\n",
    "\n",
    "从LLM转换文本->结构化信息（例如JSON）\n",
    "\n",
    "将聊天消息转换为字符串\n",
    "\n",
    "将调用返回的额外信息转换为字符串，而不是消息（如 OpenAI 函数调用）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:26:08.688533Z",
     "start_time": "2023-08-06T12:26:08.620537Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2.1.4. 大语言模型链\n",
    "我们现在可以将所有这些组合成一个链。此链将获取输入变量，将这些变量传递给提示模板以创建提示，将提示传递给 LLM，然后通过（可选）输出分析器传递输出。这是捆绑模块化逻辑的便捷方法。让我们看看它的实际效果！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T12:29:57.806785Z",
     "start_time": "2023-08-06T12:29:56.306080Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"colors\")\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
